{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is version 9 of my code, with the generator rewritten. This code features Jay's inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pandas as pd\n",
    "\n",
    "# File ops libraries\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "from numpy.random import seed\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob  # retriving an array of files in directories\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Tensorflow libraries\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_gan as tfgan\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.metrics import categorial_crossentropy\n",
    "# use tf.keras.metrics.CategorialCrossentropy\n",
    "# see https://www.tensorflow.org/api_docs/python/tf/keras/metrics/CategoricalCrossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Scikit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Allow matplotlib images to render immediately.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking datasets\n",
    "paths = os.listdir(path=\"chest_xray\")\n",
    "\n",
    "path_train = \"chest_xray/train\"\n",
    "path_val = \"chest_xray/val\"\n",
    "\n",
    "img = glob(path_train+\"/PNEUMONIA/*.jpeg\")  # Getting all images in this folder\n",
    "img = np.asarray(plt.imread(img[0]))\n",
    "\n",
    "img = glob(path_train + \"/NORMAL/*.jpeg\")  # Getting all images in this folder\n",
    "img = np.asarray(plt.imread(img[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing and analysis\n",
    "classes = [\"NORMAL\", \"PNEUMONIA\"]\n",
    "train_data = glob(path_train+\"/NORMAL/*.jpeg\")\n",
    "train_data += glob(path_train+\"/PNEUMONIA/*.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = ImageDataGenerator()  # Augmentation happens here\n",
    "# But in this example we're not going to give the ImageDataGenerator method any parameters to augment our data.\n",
    "\n",
    "\n",
    "train_batches = data_gen.flow_from_directory(\n",
    "    path_train,\n",
    "    target_size=(226, 226),\n",
    "    classes=classes,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "val_batches = data_gen.flow_from_directory(\n",
    "    path_val,\n",
    "    target_size=(226, 226),\n",
    "    classes=classes,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "test_batches = data_gen.flow_from_directory(\n",
    "    path_test,\n",
    "    target_size=(226, 226),\n",
    "    classes=classes,\n",
    "    class_mode=\"categorical\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches.image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a Convolutional Artificial Neural Network\n",
    "# VGG16 Model\n",
    "model = Sequential()\n",
    "model.add(ZeroPadding2D((1, 1), input_shape=train_batches.image_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIMISERS\n",
    "optimizer = Adam(lr=0.0001)\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(\n",
    "    patience=3,\n",
    "    monitor=\"val_acc\",\n",
    "    mode=\"max\",\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    "    optimizer=optimizer\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x=train_batches,\n",
    "    # batch_size=32,\n",
    "    epochs=5,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping_monitor],\n",
    "    validation_split=0.0,\n",
    "    validation_data=val_batches,\n",
    "    shuffle=True,\n",
    "    class_weight=None,\n",
    "    sample_weight=None,\n",
    "    initial_epoch=0,\n",
    "    steps_per_epoch=163,\n",
    "    validation_steps=10,\n",
    "    validation_freq=1,\n",
    "    max_queue_size=10,\n",
    "    workers=1,\n",
    "    use_multiprocessing=False\n",
    ")\n",
    "\n",
    "prediction = model.predict(\n",
    "    train_batches,\n",
    "    batch_size=None,\n",
    "    verbose=1,\n",
    "    steps=100,\n",
    "    callbacks=None,\n",
    "    max_queue_size=10,\n",
    "    workers=1,\n",
    "    use_multiprocessing=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('save/v7.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Source: Jason Brownlee\n",
    "Site: https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n",
    "'''\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
